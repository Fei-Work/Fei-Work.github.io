---
title: "论文阅读: L-VIWO: Visual-Inertial-Wheel Odometry based on Lane Linese"

categories:
  - blogs
tags:
  - VIO
  - SLAM
lang: zh
header: 
  teaser: "./assets/images/L-VIWO/image-20240827151650081.png"
---

在进行自动驾驶车辆定位时，常常使用车道线等路标与HD-map先验地图中的语义信息进行匹配并融合GNSS的方案。相较于直接使用里程计的方法其能够极大减少累计误差，在长时间的定位中定位精度达到分米级的效果。但先验地图的建立需要耗费大量的资源。该文章介绍了一种不使用先验地图，且使用车道线进行定位矫正的方法，附加在经典的VIO方案上定位精度有所提高。



## 方案概览

{% include image.html url="/assets/images/L-VIWO/image-20240827151650081.png" description="" %}

该文章提出的方法是一种车道线辅助里程计定位的方法，即在里程计运行过程并行进行车道线提取、跟踪。再使用里程计提供的位姿信息辅助车道线建图的优化。当检测到车辆跨线时，执行联合的图优化。该方法的主要创新点分别为车道线的建图与车道线辅助定位。

### 车道线的提取与跟踪

文章选择使用**LaneATT**进行车道线提取，使用车道线样本点来表示车道线。*这里的车道线样本点可以理解为用一系列的点来代表一个id的车道线，后续计算车辆与车道线的横向距离时会使用曲线拟合的方式将点连续化，就很方便能到的横向距离，同时，论文作者说明这种方式不挑检测网络。*

在跟踪部分，文章选择将k-1帧的像素特征点利用已知位姿信息投影到k帧的图像中，与k帧检测到的车道线计算$IOU$，并构建代价矩阵$Cost$。


$$
I O U_i^j=\frac{\operatorname{mask}_D^i \cap \operatorname{mask}_T^j}{\operatorname{mask}_D^i \cup \operatorname{mask}_T^j} \tag1
$$

其中 i 和 j 分别是车道线 ID，$D$与$T$分别表示当前帧与过去帧。并集和交集的值由相应区域掩模中的像素数量确定。

$$
\operatorname{cost}_i^j=1-I O U_i^j \tag2
$$

$$
\operatorname{Cost}=\left[\begin{array}{cccc}
\operatorname{cost}_1^1 & \operatorname{cost}_1^2 & \cdots & \operatorname{cost}_1^n \\
\cos t_2^1 & \operatorname{cost}_2^2 & \cdots & \operatorname{cost}_2^n \\
\cdots & \cdots & \cdots & \cdots \\
\operatorname{cost}_m^1 & \operatorname{cost}_m^2 & \cdots & \operatorname{cost}_m^n
\end{array}\right] \tag3
$$

这里就转化为一个分配问题，文章选择使用匈牙利算法进行求解。

<details>
    <summary>
    匈牙利算法
    </summary>
    匈牙利算法是一种分配算法思想，使得最终分配得到的总COST达到极小值，在数学建模，目标跟踪等领域很常见。本例首先要对矩阵进行0补全，使得行列相同。
        <ul>
<li>step1.选择每一行最小的元素，然后从该行的每个元素中减去它。</li>
<li>step2.选择每一列最小的元素，然后从该列的每个元素中减去它。</li>
<li>step3.使用最少数量的水平和垂直线覆盖结果矩阵中的所有零。若等于矩阵的阶数得到最佳分配，若没有则进行下一步。	</li>
<li>step4.寻找未被水平或垂直线覆盖的最小元素。从所有未被覆盖的数中减去该元素，并将k添加到所有覆盖两次的元素中。</li>
</ul>
</details>

具体步骤如图所示了。

{% include image.html url="/assets/images/L-VIWO/image-20240827153505068.png" description="" %}

### 车道线地图创建

文章认为匹配完成后直接进行车道线的拼接会对误差进行累计，所以使用了相邻帧之间可能重复观察到的部分进行的一定程度的矫正拼接，具体的方式如下。

{% include image.html url="/assets/images/L-VIWO/image-20240827163351307.png" description="" %}

首先是先使用了**IPM**模型将**新的车道线样本点**投影到了**车辆坐标系**之下，同时使用变换矩阵将**历史车道线样本点**也投影到**车辆的坐标系**下。将两者都置于统一的坐标系下这样方便后续的计算处理。

<details>
    <summary>
        IPM模型
    </summary>
    IPM模型是Inverse Perspective Mapping，即逆透视映射，一般是用于去除透视效应，使得平行线仍然是平行线，得到车体坐标下的俯视图
</details>

文章不直接衔接，那么是怎么做的呢？在Fig. 3.中可以看到，对**重复观测的样本点**取**垂直点**作为修正位置，而对于**新观测到的样本点**其将每个重复观测的样本点的横向偏移进行**加权处理**累加到原坐标点坐标上，加权主要考虑$X_v$，这是因为考虑到IPM模型的尺度恢复精度随着距离的增加而降低。*【这个部分的$\alpha_j$求取我是存疑的，后续查阅相关资料后进行补充】*

$$
\left[\begin{array}{l}
X_v^{\prime} \\
Y_v^{\prime} \\
Z_v^{\prime}
\end{array}\right]=\left[\begin{array}{c}
X_v \\
Y_v \\
0
\end{array}\right]+\alpha_1\left[\begin{array}{l}
a_1 \\
b_1 \\
c_1
\end{array}\right]+\alpha_2\left[\begin{array}{l}
a_2 \\
b_2 \\
c_2
\end{array}\right]+\cdots+\alpha_n\left[\begin{array}{l}
a_n \\
b_n \\
c_n
\end{array}\right] \tag 4
$$

$$
\alpha_j=1-\frac{X_v^j}{\sum_{i=0}^{i=n} X_v^i} \tag5
$$

式中，$\begin{bmatrix}X_v &Y_v & 0\end{bmatrix}^T$ 和 $\begin{bmatrix}X_v' &Y_v' & Z_v'\end{bmatrix}^T$ 分别为校正前后样本点的位置。$\begin{bmatrix}a_j&b_j & c_j\end{bmatrix}^T$ 是从重复观察的样本点到校正位置的平移向量。

之后这个部分还进行了较远车道线的矫正，其认为车道线的曲率应该是一致的所以用更近的一个来矫正较远的一个，这个部分不做探讨。



### 基于车道线的位姿矫正

每次车辆检测到换道的时候(*至于怎么换道，文章并未详说，这里猜测是检测到的车道线在车体坐标系中的符号发生了变化*)，就会利用车辆的横向距离与车道线图进行位姿优化。

{% include image.html url="/assets/images/L-VIWO/image-20240827190149695.png" description="" %}

首先把车道的采样点拟合成四阶的曲线，之后使用从里程计获得的车辆位置向相应的车道线画一条垂直线，并确定相应的交点。然后，沿着垂直线，我们搜索距交点距离等于横向距离的位置。我们选择车道线左侧的位置作为车辆的修正位置。**这个部分有点绕，我是这样理解的：横向距离是从车道线得来的，我们车辆位置画的垂线的横向距离是里程计得来的，作者选择综合考虑两种方法**

{% include image.html url="/assets/images/L-VIWO/image-20240827190410157.png" description="" %}

之后则是综合考虑里程计以及我们刚得到的车辆修正位置的约束，构建图优化。其中的目标函数与残差因子为：

$$
\chi^*=\arg \min _\chi\left\{\sum_{(i, j) \in O}\left\|O_{i j}\right\|^2+\sum_{(i) \in L}\left\|L_i\right\|^2\right\} \tag 6
$$

$$
O_{i j}=\left[\begin{array}{c}
\left(q_i^o\right)^{-1}\left(p_j^o-p_i^o\right)-\left(q_i^l\right)^{-1}\left(p_j^l-p_i^l\right) \\
\left(\left(q_i^o\right)^{-1} q_j^o\right)^{-1} \otimes\left(\left(q_i^l\right)^{-1} q_j^l\right)
\end{array}\right] \tag7
$$

$$
L_i=p_{X_i}^l-p_i^l\tag8
$$

公式$(7)$好理解，第一项是四元数表示的平移残差，第二项是旋转残差；公式$(8)$也很容易理解，即修正位置减去优化变量。



## 总结

该文章并未开源代码，我也并未进行复现，结果不再贴图；其论文中的实验部分中不仅展示了L-VIWO的结果，也将该Lane Lines辅助进行定位的方法用于了ORB-SLAM3以及VINS-FUSION这些开源方案中测试，结果定位准确度有一定的改进。时间复杂度分析中，由于做了并行处理，系统运行时间只有小幅度的升高，认为系统可以10Hz以上实时运行。但事实上，测试平台使用了RTX 3060显卡，计算成本仍然是增加了，文章所使用的KAIST urban数据集是城市道路数据集，在特殊天气、车道线破损等情况下并未进行讨论。

最后，论文作者在总结中写：*In future work, we will consider constraints from other road signs to improve our system further.*

**Reference**

[Zhao B, Zhang Y, Huang J, et al. L-VIWO: Visual-Inertial-Wheel Odometry based on Lane Lines[C]//2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024: 18079-18085.](https://ieeexplore.ieee.org/abstract/document/10610139/)